{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22651c08-2658-40f1-be6d-aa6e751e13c0",
   "metadata": {},
   "source": [
    "### Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you\n",
    "might choose one over the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3234f49-9daa-4fb1-b054-d85eeeb3fa46",
   "metadata": {},
   "source": [
    "Ordinal encoding and label encoding are both techniques used to represent categorical variables as numerical data. However, there are some differences between them.\n",
    "\n",
    "Ordinal encoding assigns each unique category a numerical value based on its order or rank. For example, in a dataset of T-shirt sizes (small, medium, large), ordinal encoding could assign the values 1, 2, and 3 respectively.\n",
    "\n",
    "Label encoding assigns a numerical value to each unique category in a categorical variable without any specific order or ranking. For example, in a dataset of fruit types (apple, banana, orange), label encoding could assign the values 1, 2, and 3 respectively.\n",
    "\n",
    "In general, ordinal encoding is more appropriate when there is a clear order or ranking among the categories, such as in the case of T-shirt sizes or academic degrees (e.g., associate's, bachelor's, master's, etc.). On the other hand, label encoding is more appropriate when there is no clear order or ranking among the categories, such as in the case of fruit types or car models.\n",
    "\n",
    "For instance, if you have a dataset of student grades, where the grades are represented as categorical variables (e.g., A, B, C, D, F), you can use ordinal encoding to assign a numerical value to each category based on its order (e.g., A = 5, B = 4, C = 3, D = 2, F = 1). On the other hand, if you have a dataset of different types of music (e.g., rock, jazz, pop, hip hop), you can use label encoding to assign a numerical value to each category without any specific order or ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db04ea75-9fb7-4c31-8886-a588a3dad335",
   "metadata": {},
   "source": [
    "### Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in\n",
    "a machine learning project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed07f13-4c17-4cdf-9f55-93622adf83e6",
   "metadata": {},
   "source": [
    "Target Guided Ordinal Encoding is a technique that combines the concepts of ordinal encoding and target encoding. The basic idea is to encode categorical variables based on their relationship with the target variable.\n",
    "\n",
    "In target guided ordinal encoding, we first calculate the mean of the target variable for each category in the categorical variable. Then, we sort the categories based on the mean target value, and assign a numerical value to each category based on its rank. For example, the category with the highest mean target value will be assigned the highest numerical value, and so on.\n",
    "\n",
    "Let's consider an example of a dataset that contains information about customers who have purchased different products from an online store. One of the categorical variables in the dataset is 'Product Category', which contains several categories such as 'Electronics', 'Clothing', 'Books', and so on. The target variable in this case could be 'Purchase Amount', which represents the total amount spent by the customer on the product.\n",
    "\n",
    "We can use target guided ordinal encoding to encode the 'Product Category' variable based on its relationship with the target variable 'Purchase Amount'. We can calculate the mean 'Purchase Amount' for each category, sort the categories based on the mean 'Purchase Amount', and assign a numerical value to each category based on its rank. For example, if the mean 'Purchase Amount' for 'Electronics' is the highest, it will be assigned the highest numerical value, and so on.\n",
    "\n",
    "Target guided ordinal encoding can be useful in a machine learning project when we have categorical variables that are highly correlated with the target variable. By encoding these variables in a way that reflects their relationship with the target, we can potentially improve the performance of our machine learning model. However, it is important to note that this technique may not work well if the relationship between the categorical variable and the target variable is not strong enough or if there is too much variability within each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45480043-0a68-45f6-963e-1a9b486e74f2",
   "metadata": {},
   "source": [
    "### Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7af911-69cf-4338-b671-1a112b68a626",
   "metadata": {},
   "source": [
    "Covariance is a measure of the relationship between two variables. Specifically, covariance measures how much two variables change together. If two variables have a positive covariance, it means that they tend to increase or decrease together, while if they have a negative covariance, it means that they tend to move in opposite directions.\n",
    "\n",
    "Covariance is important in statistical analysis because it helps us understand the relationship between two variables. For example, if we are interested in understanding the relationship between the price of a product and the number of units sold, we can use covariance to measure the strength of this relationship. Additionally, covariance is used in many statistical techniques, such as regression analysis, factor analysis, and principal component analysis.\n",
    "\n",
    "Covariance is calculated using the following formula:\n",
    "\n",
    "cov(X, Y) = Î£[(Xi - Xmean) * (Yi - Ymean)] / (n - 1)\n",
    "\n",
    "where X and Y are the two variables, Xi and Yi are the values of X and Y for the ith observation, Xmean and Ymean are the means of X and Y respectively, and n is the number of observations.\n",
    "\n",
    "The resulting value of covariance will be positive if X and Y tend to move in the same direction, negative if they tend to move in opposite directions, and zero if there is no relationship between X and Y. However, the magnitude of the covariance depends on the scale of the variables, which makes it difficult to compare covariances across different datasets. To overcome this limitation, we can normalize covariance to obtain the correlation coefficient, which is a standardized measure of the relationship between two variables that ranges from -1 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463eb020-eb05-4d3f-8dac-9060a16fbd65",
   "metadata": {},
   "source": [
    "### Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\n",
    "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library.\n",
    "Show your code and explain the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9a2f8-1a48-4188-abb3-09b3b11d3820",
   "metadata": {},
   "source": [
    "to perform label encoding using Python's scikit-learn library on a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48e8f90-90df-4af9-a3eb-e069bf247d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color  Size  Material\n",
      "0      2     2         2\n",
      "1      1     1         0\n",
      "2      0     0         1\n",
      "3      2     1         0\n",
      "4      0     0         2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = pd.DataFrame({\n",
    "    'Color': ['red', 'green', 'blue', 'red', 'blue'],\n",
    "    'Size': ['small', 'medium', 'large', 'medium', 'large'],\n",
    "    'Material': ['wood', 'metal', 'plastic', 'metal', 'wood']\n",
    "})\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each column in the dataset\n",
    "for column in data.columns:\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849ef97-2554-46ba-882d-055da562460f",
   "metadata": {},
   "source": [
    "The label encoder has transformed each unique value in each column into a numerical value. In this case, the values for the 'Color' column are mapped to 0, 1, and 2; the values for the 'Size' column are mapped to 0, 1, and 2; and the values for the 'Material' column are mapped to 0, 1, and 2. Note that the numerical values assigned by the label encoder do not have any specific order or ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6169f-3638-47ca-a35c-e38274b39d5c",
   "metadata": {},
   "source": [
    "### Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\n",
    "level. Interpret the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e451ed-1413-4090-bcd2-015b4a7d7209",
   "metadata": {},
   "source": [
    "the covariance matrix for the variables Age, Income, and Education level, we need a dataset that includes these variables. Assuming we have such a dataset, we can use Python's NumPy library to calculate the covariance matrix as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce1fd6-9318-48e3-87a5-8c905c5f6000",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "data = pd.read_csv('filename.csv')\n",
    "\n",
    "# Select the columns for which we want to calculate the covariance matrix\n",
    "selected_cols = ['Age', 'Income', 'Education_level']\n",
    "\n",
    "# Calculate the covariance matrix using numpy's cov function\n",
    "cov_matrix = np.cov(data[selected_cols].T)\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3cd7d-8430-4cc0-9336-1f1273eee1ba",
   "metadata": {},
   "source": [
    "### Q6. You are working on a machine learning project with a dataset containing several categorical\n",
    "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\n",
    "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
    "each variable, and why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b2911-fd84-4ed2-8886-5a09b6a1fd9b",
   "metadata": {},
   "source": [
    "For the given categorical variables \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time), the choice of encoding method depends on the nature of the variable and the type of machine learning algorithm being used. Here are some options:\n",
    "\n",
    "For \"Gender\": Since this variable has only two possible values (Male and Female), we can use binary encoding or label encoding. Binary encoding is a good choice when the categorical variable has only two categories. However, in this case, we can also use label encoding because there is a natural ordering to the categories (e.g., 0 for Male and 1 for Female).\n",
    "\n",
    "For \"Education Level\": Since this variable has multiple levels that do not have a natural order or ranking, we can use one-hot encoding. This method creates a separate binary column for each category, where 1 indicates that the sample belongs to that category and 0 indicates that it does not. One-hot encoding is a good choice when the categorical variable has multiple categories and there is no inherent ordering or ranking between them.\n",
    "\n",
    "For \"Employment Status\": Similar to \"Education Level\", this variable has multiple levels that do not have a natural order or ranking. Thus, one-hot encoding is a good choice for this variable as well.\n",
    "\n",
    "In summary, for the given categorical variables, we can use binary or label encoding for \"Gender\" and one-hot encoding for \"Education Level\" and \"Employment Status\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38e98-9827-4b13-84c2-8c6f6d84dcf7",
   "metadata": {},
   "source": [
    "### Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two\n",
    "categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\n",
    "East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5795a033-fcaf-4fac-8fef-1f9a22d06a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'filename.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the dataset into a pandas dataframe\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Select the columns for which we want to calculate the covariance matrix\u001b[39;00m\n\u001b[1;32m      8\u001b[0m selected_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTemperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHumidity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeather Condition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWind Direction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filename.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "data = pd.read_csv('filename.csv')\n",
    "\n",
    "# Select the columns for which we want to calculate the covariance matrix\n",
    "selected_cols = ['Temperature', 'Humidity', 'Weather Condition', 'Wind Direction']\n",
    "\n",
    "# Calculate the covariance matrix using numpy's cov function\n",
    "cov_matrix = np.cov(data[selected_cols].T)\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f472e-0969-4ef8-89ef-0e34a7aaf52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
