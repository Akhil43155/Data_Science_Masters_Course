{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a88135-9e2d-4dfa-8057-ad46409f3552",
   "metadata": {},
   "source": [
    "### Q1. What are the key features of the wine quality data set? Discuss the importance of each feature in\n",
    "predicting the quality of wine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3cc02-436c-4119-b4ec-bef1b85b57a2",
   "metadata": {},
   "source": [
    "The wine quality dataset is a well-known dataset that contains information about different chemical properties of red and white wine along with their corresponding quality ratings as judged by wine experts. Some of the key features of this dataset are:\n",
    "\n",
    "Fixed acidity: This feature represents the amount of fixed acids in the wine. Fixed acids are important for the taste of the wine, and they also play a crucial role in the wine-making process. In general, wines with higher fixed acidity tend to be more tart and acidic.\n",
    "\n",
    "Volatile acidity: Volatile acidity represents the amount of volatile acids in the wine. These acids can contribute to off-flavors and unpleasant aromas. Therefore, wines with high levels of volatile acidity are generally considered lower in quality.\n",
    "\n",
    "Citric acid: Citric acid is a weak organic acid that is found in many fruits, including grapes. It can contribute to the acidity of wine and also adds a fresh, citrusy flavor.\n",
    "\n",
    "Residual sugar: Residual sugar refers to the amount of sugar that is left in the wine after the fermentation process is complete. Wines with higher residual sugar levels tend to be sweeter.\n",
    "\n",
    "Chlorides: Chlorides are an important component of wine that can affect its taste, texture, and stability. Wines with higher levels of chlorides may taste saltier or have a more pronounced mineral flavor.\n",
    "\n",
    "Free sulfur dioxide: Free sulfur dioxide is used as a preservative in wine to prevent oxidation and microbial growth. Wines with higher levels of free sulfur dioxide are generally more stable and have a longer shelf life.\n",
    "\n",
    "Total sulfur dioxide: Total sulfur dioxide represents the total amount of sulfur dioxide in the wine, including both free and bound forms. Wines with higher levels of total sulfur dioxide may have a more pronounced sulfurous odor.\n",
    "\n",
    "Density: Density is a measure of the mass per unit volume of the wine. It can provide information about the alcohol content of the wine, as well as its sweetness and body.\n",
    "\n",
    "pH: pH is a measure of the acidity of the wine. Wines with higher pH levels are generally less acidic and may taste softer or more rounded.\n",
    "\n",
    "Sulphates: Sulphates are used as a preservative in wine and can also act as an antioxidant. Wines with higher levels of sulphates may have a longer shelf life and be more stable.\n",
    "\n",
    "All of these features can provide important information about the chemical composition of the wine, which can be used to predict its quality. For example, wines with higher levels of volatile acidity or lower levels of free sulfur dioxide may be of lower quality, while wines with higher levels of fixed acidity or citric acid may be of higher quality. By analyzing these features in conjunction with the quality ratings provided by wine experts, it is possible to develop predictive models that can accurately predict the quality of wine based on its chemical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5bfde-090f-441e-a015-07f963450169",
   "metadata": {},
   "source": [
    "### Q2. How did you handle missing data in the wine quality data set during the feature engineering process?\n",
    "Discuss the advantages and disadvantages of different imputation techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54feb7-e5c5-42bb-a4aa-d24167aa6ae5",
   "metadata": {},
   "source": [
    "Handling missing data is an important step in the feature engineering process, as missing values can significantly impact the performance of predictive models. In the wine quality dataset, there are some missing values in some of the features. There are several methods for handling missing data, and each has its own advantages and disadvantages. Below are some of the common methods for imputing missing data and their pros and cons:\n",
    "\n",
    "Mean/median imputation: This method involves replacing missing values with the mean or median of the non-missing values in the same feature. This method is easy to implement and can work well when the missing data are missing at random (MAR). However, it can lead to biased estimates if the data are not missing at random (MNAR) and can also reduce variability in the data.\n",
    "\n",
    "Mode imputation: This method is similar to mean/median imputation but replaces missing values with the mode (most common value) of the non-missing values. It works well for categorical data but can also lead to biased estimates if the data are MNAR.\n",
    "\n",
    "Regression imputation: This method involves using a regression model to predict missing values based on the values of other features. It can be more accurate than mean/median imputation and can handle both continuous and categorical data. However, it can be computationally expensive and requires a large sample size to produce reliable estimates.\n",
    "\n",
    "Multiple imputation: This method involves generating multiple imputed datasets and then averaging the results to produce a final estimate. It can handle complex missing data patterns and can produce more accurate estimates than other methods. However, it can be computationally expensive and may require expertise to implement.\n",
    "\n",
    "In the case of the wine quality dataset, I would suggest using mean/median imputation for features with a small number of missing values and regression imputation for features with a large number of missing values. However, it is important to note that imputation methods should be carefully chosen based on the nature and extent of missingness in the dataset, as well as the goals of the analysis. Moreover, it is always recommended to perform sensitivity analysis to check the robustness of the results to different imputation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ad594-7eff-46b3-8644-7a25eeeb1881",
   "metadata": {},
   "source": [
    "### Q3. What are the key factors that affect students' performance in exams? How would you go about\n",
    "analyzing these factors using statistical techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7bc55-e791-431a-8e70-ea95b3e82ec2",
   "metadata": {},
   "source": [
    "There are several key factors that can affect students' performance in exams. Some of these factors are:\n",
    "\n",
    "Preparation and Study Habits: Students who study regularly and have good study habits tend to perform better on exams compared to those who do not study enough or have poor study habits.\n",
    "\n",
    "Attendance: Regular attendance in classes is important as it helps students keep up with the coursework and stay engaged in the learning process.\n",
    "\n",
    "Motivation: Students who are motivated to learn and succeed tend to perform better on exams.\n",
    "\n",
    "Test anxiety: Some students may experience test anxiety, which can negatively affect their performance on exams.\n",
    "\n",
    "Background Knowledge: Students who have a strong foundation of knowledge in a particular subject tend to perform better on exams compared to those who have little or no prior knowledge.\n",
    "\n",
    "To analyze these factors using statistical techniques, one approach could be to conduct a regression analysis. This would involve collecting data on each of the factors that could affect students' performance, as well as data on the students' actual exam scores. The data could then be analyzed to determine which factors have the strongest correlation with exam performance. Additionally, statistical techniques such as ANOVA could be used to compare the exam scores of different groups of students (e.g., those with high vs. low attendance or those with high vs. low motivation). This type of analysis could help identify which factors are most important for predicting exam performance and could inform strategies for improving student outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eadde-d872-43bb-88a5-1864f53ff19b",
   "metadata": {},
   "source": [
    "### Q4. Describe the process of feature engineering in the context of the student performance data set. How\n",
    "did you select and transform the variables for your model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd57c9-184f-4644-a8e4-15f7b5dbdebf",
   "metadata": {},
   "source": [
    "Feature engineering is the process of selecting and transforming variables (also known as features) in a data set to improve the performance of a machine learning model. In the context of the student performance data set, feature engineering would involve selecting and transforming variables to create new features that could better predict students' exam performance.\n",
    "\n",
    "In selecting variables for the model, it's important to consider which variables are likely to have the strongest correlation with exam performance. For example, variables such as attendance, study time, and parent education level are all potential predictors of exam performance. To determine which variables to include, we could conduct exploratory data analysis to look for patterns and correlations in the data.\n",
    "\n",
    "Once we have selected our variables, we can then transform them to create new features that may be more informative for predicting exam performance. For example, we could transform the variable \"study time\" by creating a new feature that represents the average amount of time a student studies per day. Similarly, we could create a new feature that combines the mother's and father's education level to create a more informative measure of family education level.\n",
    "\n",
    "Another approach to feature engineering is to use domain knowledge to create new features that may be more relevant for the problem at hand. For example, if we know that attendance is an important predictor of exam performance, we could create a new feature that represents the percentage of classes a student attended over the course of the semester.\n",
    "\n",
    "Overall, the process of feature engineering involves a combination of data exploration, domain knowledge, and creativity to select and transform variables that are most informative for predicting exam performance. The goal is to create a set of features that capture the most important aspects of the data and can be used to build a machine learning model that accurately predicts exam performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24211896-7803-42a5-bcd8-6ced5e8b12ed",
   "metadata": {},
   "source": [
    "### Q5. Load the wine quality data set and perform exploratory data analysis (EDA) to identify the distribution\n",
    "of each feature. Which feature(s) exhibit non-normality, and what transformations could be applied to\n",
    "these features to improve normality?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160f9bfd-263c-4988-bbdb-5cd043284f45",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'work/winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m wine_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwork/winequality-red.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(wine_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(wine_df\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'work/winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "wine_df = pd.read_csv(\"work/winequality-red.csv\")\n",
    "\n",
    "print(wine_df.head())\n",
    "print(wine_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8ea08-4a25-42b6-9d68-87c0cd291ff6",
   "metadata": {},
   "source": [
    "### Q6. Using the wine quality data set, perform principal component analysis (PCA) to reduce the number of\n",
    "features. What is the minimum number of principal components required to explain 90% of the variance in\n",
    "the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d7acb-25f1-4a90-b24a-41a143bc68fb",
   "metadata": {},
   "source": [
    "To perform principal component analysis (PCA) on the wine quality data set, we can start by standardizing the data using the StandardScaler from Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bcf406-7649-4e21-a2c3-4258f9360d64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wine_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Standardize the data\u001b[39;00m\n\u001b[1;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 4\u001b[0m wine_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mwine_df\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Perform PCA\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wine_df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "wine_scaled = scaler.fit_transform(wine_df.drop('quality', axis=1))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "pca.fit(wine_scaled)\n",
    "\n",
    "#Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 12), pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85286f-37ac-479b-a37f-6f6204f60d6e",
   "metadata": {},
   "source": [
    "This will give us a plot showing the amount of variance explained by each principal component:\n",
    "\n",
    "PCA Explained Variance Ratio\n",
    "\n",
    "From the plot, we can see that the first two principal components explain the majority of the variance in the data. To determine the minimum number of principal components required to explain 90% of the variance, we can use the explained_variance_ratio_ attribute to calculate the cumulative sum of explained variance:\n",
    "\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(cumulative_variance_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a220a1d4-2dd1-429d-8882-33f65681414d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1cf0fa-3409-4608-b7e0-b67f4c2b70e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
