{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b12588-b678-49fb-9624-3d630c173da8",
   "metadata": {},
   "source": [
    "### Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be626eb1-3b63-4f0c-b164-8d2c442c9b1a",
   "metadata": {},
   "source": [
    "Polynomial functions are a type of mathematical function used in many machine learning algorithms, including SVMs. Kernel functions, on the other hand, are a type of function used in SVMs to transform data into a higher-dimensional space where it may be more easily separable.\n",
    "\n",
    "In the context of SVMs, polynomial kernel functions are a type of kernel function that use polynomial functions to transform the data into a higher-dimensional space. Specifically, the polynomial kernel function computes the inner product of two polynomial functions in the original feature space, which effectively maps the data to a higher-dimensional space.\n",
    "\n",
    "The degree of the polynomial kernel function determines the degree of the polynomial function used to transform the data. For example, a polynomial kernel function of degree 2 corresponds to a quadratic polynomial function.\n",
    "\n",
    "Overall, polynomial functions and kernel functions are related in that polynomial functions can be used to construct polynomial kernel functions, which are a type of kernel function used in SVMs to transform data into a higher-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a65aa-df32-4058-aa51-669b9f3b1e77",
   "metadata": {},
   "source": [
    "### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffad42ae-b4c6-44c4-a81f-56b54642407d",
   "metadata": {},
   "source": [
    "To implement an SVM with a polynomial kernel in Python using Scikit-learn, we can use the SVC (Support Vector Classifier) class and specify the kernel parameter as 'poly'. We also need to specify the degree parameter, which controls the degree of the polynomial kernel function.\n",
    "\n",
    "Here is an example code snippet that demonstrates how to implement an SVM with a polynomial kernel in Python using Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8606fb5a-8dca-4022-abe6-953d67ad9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a SVM classifier with a polynomial kernel\n",
    "svm = SVC(kernel='poly', degree=2)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "accuracy = svm.score(X_test, y_test)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d63d7-8a4d-4101-9368-75a0db01e16e",
   "metadata": {},
   "source": [
    "### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae593a4-f515-458a-9aee-68cde26315c0",
   "metadata": {},
   "source": [
    "In SVR (Support Vector Regression), the parameter epsilon (ε) is used to define the width of the margin around the regression line. It determines the minimum distance between the predicted value and the actual value that is allowed to be considered as an accurate prediction.\n",
    "\n",
    "When the value of epsilon is increased, the margin around the regression line widens. This means that more data points can fall within the margin and still be considered accurate predictions. As a result, the number of support vectors can increase as well.\n",
    "\n",
    "If we increase epsilon to a large value, it may result in a larger number of support vectors. This is because a larger margin means that more data points can fall within the margin, and the model needs to use more support vectors to define the margin.\n",
    "\n",
    "However, the impact of epsilon on the number of support vectors also depends on the complexity of the dataset and the specific value of epsilon. In some cases, increasing epsilon may lead to a decrease in the number of support vectors as it can cause the model to become less sensitive to smaller fluctuations in the data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b00eb11-9e62-4eb8-8f51-61a802de14cb",
   "metadata": {},
   "source": [
    "### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dfce9-e5f0-4a55-85da-48c5f64f1b87",
   "metadata": {},
   "source": [
    "The performance of Support Vector Regression (SVR) is affected by several parameters, including the kernel function, C parameter, epsilon parameter, and gamma parameter. Here's a brief explanation of each parameter and how it affects the performance of SVR:\n",
    "\n",
    "Kernel function: The kernel function determines the type of decision boundary that the SVM will create. In SVR, common kernel functions include linear, polynomial, and radial basis function (RBF) kernels. The choice of kernel function depends on the complexity of the dataset and the type of decision boundary that is appropriate for the problem.\n",
    "\n",
    "C parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error. A smaller value of C creates a wider margin, which may lead to more training errors but a better generalization performance. On the other hand, a larger value of C creates a narrower margin, which may lead to fewer training errors but poorer generalization performance. Therefore, a larger value of C is useful when the model needs to fit the data accurately, while a smaller value is useful when the model needs to have better generalization performance.\n",
    "\n",
    "Epsilon parameter: The epsilon parameter defines the margin of tolerance around the predicted value. A larger value of epsilon allows more errors in the prediction, which can result in a wider margin and fewer support vectors. Conversely, a smaller value of epsilon leads to a narrower margin and more support vectors. Therefore, a larger value of epsilon is useful when the model needs to be more tolerant of errors in the predictions, while a smaller value is useful when the model needs to be more accurate.\n",
    "\n",
    "Gamma parameter: The gamma parameter determines the influence of a single training example. A larger value of gamma leads to a more complex decision boundary and may cause overfitting, while a smaller value of gamma leads to a simpler decision boundary and may cause underfitting. Therefore, a larger value of gamma is useful when the model needs to capture more complex relationships between the features and the target variable, while a smaller value is useful when the model needs to be less complex.\n",
    "\n",
    "Here are some examples of when you might want to increase or decrease each parameter:\n",
    "\n",
    "Kernel function: If the dataset has a linearly separable structure, a linear kernel is appropriate. If the dataset has a complex structure with many non-linear relationships, an RBF kernel may be more suitable.\n",
    "\n",
    "C parameter: If the model is underfitting and has poor training performance, you may want to increase the value of C to create a narrower margin and reduce the number of training errors. Conversely, if the model is overfitting and has poor generalization performance, you may want to decrease the value of C to create a wider margin and improve generalization.\n",
    "\n",
    "Epsilon parameter: If the model needs to be more tolerant of errors in the predictions, you may want to increase the value of epsilon to widen the margin and allow more errors. Conversely, if the model needs to be more accurate, you may want to decrease the value of epsilon to narrow the margin and reduce errors.\n",
    "\n",
    "Gamma parameter: If the model needs to capture more complex relationships between the features and the target variable, you may want to increase the value of gamma to create a more complex decision boundary. Conversely, if the model needs to be less complex, you may want to decrease the value of gamma to create a simpler decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1f1fc-ade6-4f31-a919-1a00971d9a14",
   "metadata": {},
   "source": [
    "### Q5. Assignment:\n",
    " \t Import the necessary libraries and load the dataseg\n",
    "\t Split the dataset into training and testing setZ\n",
    "  Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
    "  Create an instance of the SVC classifier and train it on the training datW\n",
    "  hse the trained classifier to predict the labels of the testing datW\n",
    "  Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
    "precision, recall, F1-scoreK\n",
    "  Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
    "improve its performanc_\n",
    "  Train the tuned classifier on the entire dataseg\n",
    "  Save the trained classifier to a file for future use.\n",
    "\n",
    "You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
    "classification and has a sufficient number of features and samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103bcfac-6038-4d0c-82c5-b9180745ee91",
   "metadata": {},
   "source": [
    "#### For this assignment, I will be using the famous Iris dataset for classification.\n",
    "\n",
    "Step 1: Importing the necessary libraries and loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b81c2b-5ed8-46a9-bd4a-9752beddc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be07305e-ac55-4ef9-b279-673b43ccdb9a",
   "metadata": {},
   "source": [
    "Step 2: Splitting the dataset into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce79f38-0e4f-49c6-8ea5-5ef8fe598b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11816e2-d729-4aa9-ad9d-c7dc7163ddbc",
   "metadata": {},
   "source": [
    "Step 3: Preprocessing the data by scaling it using the StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d15ecf-ad39-45d4-9e57-9a467bc67c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01deed4-a3aa-4cdd-b9b3-3db51ffc1225",
   "metadata": {},
   "source": [
    "Step 4: Creating an instance of the SVC classifier and training it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0a286d-2372-413b-834d-f3c8e5a52c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af43237f-292d-44ae-a886-73467cc4ab42",
   "metadata": {},
   "source": [
    "Step 5: Using the trained classifier to predict the labels of the testing data and evaluating the performance using accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ffdb41-cba8-4288-b41a-8fdb3c9e1519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad825a-ada3-4ad0-9468-42e8726b9bd5",
   "metadata": {},
   "source": [
    "Step 6: Tuning the hyperparameters of the SVC classifier using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80879056-2d3e-422a-af2d-aadc324c83a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.375 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=100, kernel=rbf;, score=0.333 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=10, kernel=rbf;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=100, kernel=rbf;, score=0.542 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END ........C=1, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=10, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END ........C=10, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=10, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END ........C=10, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=100, kernel=rbf;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ....C=100, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=10, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=10, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=10, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .......C=100, gamma=10, kernel=rbf;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END .......C=100, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 3/5] END .......C=100, gamma=10, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .......C=100, gamma=10, kernel=rbf;, score=0.792 total time=   0.0s\n",
      "[CV 5/5] END .......C=100, gamma=10, kernel=rbf;, score=0.917 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=100, kernel=linear;, score=0.958 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=100, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=100, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=100, gamma=100, kernel=rbf;, score=0.583 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=100, kernel=rbf;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=100, kernel=rbf;, score=0.417 total time=   0.0s\n",
      "Best parameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Best score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "# define the parameter grid\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# create a GridSearchCV object\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, verbose=3)\n",
    "\n",
    "# fit the GridSearchCV object to the data\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the best parameters and best score\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14dac6-99e6-4f0c-9d7e-ae49b73f33b1",
   "metadata": {},
   "source": [
    "Step 7: Training the tuned classifier on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94288801-95fd-4ce2-830a-81c42d22f9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the tuned classifier on the entire dataset\n",
    "svc_tuned = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "svc_tuned.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d275f3a1-7d32-471b-9f0a-bfb8a33e7684",
   "metadata": {},
   "source": [
    "Step 8: Saving the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea790701-7f2d-49af-a773-ed46a44caadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained classifier to a file\n",
    "filename = 'svm_iris.sav'\n",
    "pickle.dump(svc_tuned, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00106c2d-0548-43a3-b56a-e5886075fe7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m]}\n\u001b[1;32m     33\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m), param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_scaled\u001b[49m, y)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# train the tuned classifier on the entire dataset\u001b[39;00m\n\u001b[1;32m     37\u001b[0m tuned_svc \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m, C\u001b[38;5;241m=\u001b[39mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m], gamma\u001b[38;5;241m=\u001b[39mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# create an instance of the SVC classifier and train it on the training data\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# use the trained classifier to predict the labels of the testing data and evaluate the performance using accuracy score\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# tune the hyperparameters using GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=5)\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "# train the tuned classifier on the entire dataset\n",
    "tuned_svc = SVC(kernel='rbf', C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'])\n",
    "tuned_svc.fit(X_scaled, y)\n",
    "\n",
    "# save the trained classifier to a file for future use\n",
    "with open('tuned_svc.pkl', 'wb') as f:\n",
    "    pickle.dump(tuned_svc, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3d7d5-363b-4d06-b73c-703e9283be03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa4708-f527-4b0d-b6aa-d68ef0882b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
